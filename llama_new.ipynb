{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Install required libraries\n",
    "%pip install --upgrade pip\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "%pip install tensorflow scikit-learn pandas numpy matplotlib seaborn sentencepiece transformers accelerate huggingface_hub bitsandbytes diffusers safetensors xformers peft wordcloud textblob aif360 datasets requests nltk pillow scikit-learn vaderSentiment\n",
    "\n",
    "# Install additional tools and model-specific packages\n",
    "%pip install git+https://github.com/openai/CLIP.git\n",
    "%pip install ftfy regex tqdm ninja\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    CLIPProcessor,\n",
    "    CLIPModel,\n",
    "    BlipProcessor,\n",
    "    BlipForConditionalGeneration,\n",
    "    BitsAndBytesConfig,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline\n",
    ")\n",
    "from diffusers import DiffusionPipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import ttest_ind\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import PEFT for fine-tuning models\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# Check versions of critical libraries\n",
    "print(f\"BitsAndBytes version: {bnb.__version__}\")\n",
    "\n",
    "# Additional NLP setup\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "# System and Utility Libraries\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# NLP and Transformers\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    CLIPProcessor,\n",
    "    CLIPModel,\n",
    "    BlipProcessor,\n",
    "    BlipForConditionalGeneration,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# BitsAndBytes for Model Optimization\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Diffusers\n",
    "from diffusers.utils import pt_to_pil\n",
    "\n",
    "# Image Processing\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# SpaCy\n",
    "import spacy\n",
    "\n",
    "from huggingface_hub import login, notebook_login  # Add this import\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "import tensorflow as tf  # Add this import\n",
    "import copy  # Add this import\n",
    "import requests  # Add this import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: six in c:\\users\\rawan\\appdata\\roaming\\python\\python312\\site-packages (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: urllib3 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2019.11.28)\n",
      "Requirement already satisfied: torch>=2.1.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (2.5.1+cu118)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.9.0)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rawan\\appdata\\roaming\\python\\python312\\site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning) (0.11.9)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.10.10)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\rawan\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.57.0->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.17.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rawan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: psutil in c:\\users\\rawan\\appdata\\roaming\\python\\python312\\site-packages (6.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Number of GPUs available: 1\n",
      "Using device: cuda:0\n",
      "Using device: cuda:1\n",
      "GPU available: True\n",
      "Device: 0\n",
      "Your runtime has 68.4 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n",
      "Using CPU only\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "%pip install six\n",
    "%pip install --upgrade urllib3 requests pytorch-lightning\n",
    "import torch\n",
    "import os\n",
    "import tensorflow as tf\n",
    "%pip install psutil\n",
    "import psutil\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# Set the device to GPU 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Set the device to GPU 1\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.current_device())\n",
    "ram_gb = psutil.virtual_memory().total / 1e9  # Use psutil.virtual_memory()\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime!')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"  # as nvida gpu is gpu1, while intel gpu is gpu0\n",
    "os.environ[\"PYTHONHASHSEED\"]=\"1\"\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU only')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b3417cecbf429185c79d2665d45589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login, notebook_login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "token = \"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\"  # Replace with the token you just created\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=token)\n",
    "\n",
    "# For notebook login (if needed)\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87b8a135e724bf5ba544a0a106373d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0c62acfbb1443f9c7868b4306b3ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00030.safetensors:  22%|##1       | 1.09G/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.3-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
